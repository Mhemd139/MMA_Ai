{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AkASBND5Kzo6",
    "outputId": "67b30f95-86bc-4328-9d8e-9f1cfce364e7"
   },
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers datasets torch torchvision pillow opencv-python matplotlib seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LQuA_FWiLpeV"
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from datasets import Dataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "xkAcQdW-ReZF",
    "outputId": "44776d90-cdfc-4015-892c-639b2a074707"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import zipfile\n",
    "\n",
    "# Upload your data\n",
    "print(\"üì§ Upload your mma_data.zip file...\")\n",
    "uploaded = files.upload()\n",
    "\n",
    "# Extract the data\n",
    "print(\"ÔøΩÔøΩ Extracting data...\")\n",
    "with zipfile.ZipFile('mma_data.zip', 'r') as zip_ref:\n",
    "    zip_ref.extractall('.')\n",
    "\n",
    "print(\"‚úÖ Data extracted successfully!\")\n",
    "print(\"üìÅ Available folders:\")\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3IoJpWSRfkH",
    "outputId": "d62194fe-2557-4c9f-bece-c9229485c0b5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "print(\"üîß Fixing file structure...\")\n",
    "\n",
    "# Create the proper directories\n",
    "os.makedirs('data/blocked_punches', exist_ok=True)\n",
    "os.makedirs('data/landed_punches', exist_ok=True)\n",
    "os.makedirs('data/frames', exist_ok=True)\n",
    "\n",
    "# Move files to correct locations\n",
    "print(\"üìÅ Moving blocked punches...\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.startswith(\"data\\\\blocked_punches\\\\\"):\n",
    "        new_name = file.replace(\"data\\\\blocked_punches\\\\\", \"\")\n",
    "        shutil.move(file, f\"data/blocked_punches/{new_name}\")\n",
    "\n",
    "print(\"üìÅ Moving landed punches...\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.startswith(\"data\\\\landed_punches\\\\\"):\n",
    "        new_name = file.replace(\"data\\\\landed_punches\\\\\", \"\")\n",
    "        shutil.move(file, f\"data/landed_punches/{new_name}\")\n",
    "\n",
    "print(\"üìÅ Moving frames...\")\n",
    "for file in os.listdir('.'):\n",
    "    if file.startswith(\"data\\\\frames\\\\\"):\n",
    "        new_name = file.replace(\"data\\\\frames\\\\\", \"\")\n",
    "        shutil.move(file, f\"data/frames/{new_name}\")\n",
    "\n",
    "print(\"‚úÖ File structure fixed!\")\n",
    "print(\"üìÅ Checking folders:\")\n",
    "!ls -la data/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xkwqbGj1QV_j"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "id": "w5iR6uxaLv2c",
    "outputId": "6b3716de-f412-492a-f571-f6c74875fa5a"
   },
   "outputs": [],
   "source": [
    "# Count frames in each folder\n",
    "blocked_dir = \"data/blocked_punches\"\n",
    "landed_dir = \"data/landed_punches\"\n",
    "frames_dir = \"data/frames\"\n",
    "\n",
    "blocked_count = len([f for f in os.listdir(blocked_dir) if f.endswith('.jpg')])\n",
    "landed_count = len([f for f in os.listdir(landed_dir) if f.endswith('.jpg')])\n",
    "frames_count = len([f for f in os.listdir(frames_dir) if f.endswith('.jpg')])\n",
    "\n",
    "print(f\"ÔøΩÔøΩ Dataset Statistics:\")\n",
    "print(f\"   üõ°Ô∏è Blocked punches: {blocked_count} frames\")\n",
    "print(f\"   üí• Landed punches: {landed_count} frames\")\n",
    "print(f\"   ÔøΩÔøΩ Total video frames: {frames_count} frames\")\n",
    "print(f\"   üìà Total training samples: {blocked_count + landed_count}\")\n",
    "\n",
    "# Visualize distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Pie chart\n",
    "labels = ['Blocked', 'Landed']\n",
    "sizes = [blocked_count, landed_count]\n",
    "colors = ['#ff6b6b', '#4ecdc4']\n",
    "ax1.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "ax1.set_title('Punch Classification Distribution')\n",
    "\n",
    "# Bar chart\n",
    "ax2.bar(labels, sizes, color=colors)\n",
    "ax2.set_title('Frame Count by Class')\n",
    "ax2.set_ylabel('Number of Frames')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 637
    },
    "id": "rACzca8CLy0d",
    "outputId": "bbbfee45-1911-42f3-f658-16bd7fd646df"
   },
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "def show_samples(folder, title, num_samples=3):\n",
    "    files = [f for f in os.listdir(folder) if f.endswith('.jpg')][:num_samples]\n",
    "\n",
    "    fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))\n",
    "    if num_samples == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        img = Image.open(os.path.join(folder, file))\n",
    "        axes[i].imshow(img)\n",
    "        axes[i].set_title(f'{title} Sample {i+1}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show samples\n",
    "show_samples(blocked_dir, \"Blocked Punch\", 3)\n",
    "show_samples(landed_dir, \"Landed Punch\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266,
     "referenced_widgets": [
      "3a241ef6d431469e96c52ea1e27453d1",
      "c5f4a1bdbf2e435cb1cccc80d5722c53",
      "de315e2a039647a4bd66385d56cb0e53",
      "e40e317a47f0434396ee6190cd8818b2",
      "7b4edd741eac4a68b49108d8adcc60b4",
      "24c804081ed848219ae560e00f283a5d",
      "6c965b2ed8d44a76941b388dfa5d7d6f",
      "e7a7ae9045f0440f8b44dd4aa18264ba",
      "36064bfb8f974581a90e8070ac1f0072",
      "b10069c780664aadaad64c4bde4d26ad",
      "df61896b2eba4b1e91da993694203bc3"
     ]
    },
    "id": "Vkce4WAmL1pU",
    "outputId": "864d2429-7551-4fcb-cc37-41ee3c829c54"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PunchDataset(Dataset):\n",
    "    def __init__(self, blocked_dir, landed_dir, processor):\n",
    "        self.processor = processor\n",
    "        self.images = []\n",
    "        self.labels = []\n",
    "\n",
    "        # Load blocked punches (label 0)\n",
    "        print(\"üì• Loading blocked punches...\")\n",
    "        for frame_file in os.listdir(blocked_dir):\n",
    "            if frame_file.endswith(\".jpg\"):\n",
    "                frame_path = os.path.join(blocked_dir, frame_file)\n",
    "                try:\n",
    "                    image = Image.open(frame_path).convert(\"RGB\")\n",
    "                    self.images.append(image)\n",
    "                    self.labels.append(0)  # 0 = blocked\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipping {frame_file}: {e}\")\n",
    "\n",
    "        # Load landed punches (label 1)\n",
    "        print(\"üì• Loading landed punches...\")\n",
    "        for frame_file in os.listdir(landed_dir):\n",
    "            if frame_file.endswith(\".jpg\"):\n",
    "                frame_path = os.path.join(landed_dir, frame_file)\n",
    "                try:\n",
    "                    image = Image.open(frame_path).convert(\"RGB\")\n",
    "                    self.images.append(image)\n",
    "                    self.labels.append(1)  # 1 = landed\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Skipping {frame_file}: {e}\")\n",
    "\n",
    "        print(f\"‚úÖ Dataset prepared: {len(self.images)} images\")\n",
    "        print(f\"   Blocked punches: {self.labels.count(0)}\")\n",
    "        print(f\"   Landed punches: {self.labels.count(1)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Process image with the processor\n",
    "        inputs = self.processor(image, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": inputs[\"pixel_values\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Setup processor first\n",
    "model_name = \"microsoft/resnet-50\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Create custom dataset\n",
    "full_dataset = PunchDataset(blocked_dir, landed_dir, processor)\n",
    "\n",
    "# Split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_indices, test_indices = train_test_split(\n",
    "    range(len(full_dataset)),\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=[full_dataset.labels[i] for i in range(len(full_dataset))]\n",
    ")\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = torch.utils.data.Subset(full_dataset, train_indices)\n",
    "eval_dataset = torch.utils.data.Subset(full_dataset, test_indices)\n",
    "\n",
    "print(f\"\\nüìä Split Statistics:\")\n",
    "print(f\"   Training: {len(train_dataset)} samples\")\n",
    "print(f\"   Testing: {len(eval_dataset)} samples\")\n",
    "\n",
    "# Test a sample\n",
    "sample = train_dataset[0]\n",
    "print(f\"‚úÖ Sample test successful! Shape: {sample['pixel_values'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 260,
     "referenced_widgets": [
      "78563a8aacd1492c8132c7a825eff59d",
      "be053db47e58454ea033972d9fa85b45",
      "b1c8cd855e7c49a4aeabb46f7ed45150",
      "01ed80ea347445cb8a1937f906ef18fc",
      "220e5f58be194096a1d508d325228506",
      "9f1097f0fa9540b4a82aba9f2ae669fc",
      "3fc06b5c629d44dfbc4fe838bd0b32ac",
      "67dd2e142ffb45c8a24fd763d1016441",
      "4fcae01f21af4e45b7c1e531cc17979c",
      "a4bb0d096b5f4200abca081c932559b4",
      "7c1f2af9068a4d6daa38c65a5b7f6597",
      "b19b6244106046c09aca005cdefacfbc",
      "70061aea2b5242659b28d6a345528ce3",
      "0f676ef8032a45508d4c29eccf36ad7a",
      "bdcf2e9987394233aa1ec2e72a6480d6",
      "4d437a1ef6e748a5a2316f5aad78f5ed",
      "1e2897ff189e4511a93ba59fc13770ba",
      "41f89d31f8db40a597c82c65f95b3bba",
      "da750a2e77c043d9919b922850cb6071",
      "54688bd9ec814c3689df65a6b8cac12a",
      "5aadf8d7f92946e1b783ac97d2926443",
      "4a7da7a61039401481ed2511d41a39e6"
     ]
    },
    "id": "_B5LrlBkL4n6",
    "outputId": "f77b6547-2e85-4961-ffe1-f94d75c2584d"
   },
   "outputs": [],
   "source": [
    "def setup_huggingface_model():\n",
    "    \"\"\"Setup the Hugging Face model for fine-tuning\"\"\"\n",
    "    print(\" Setting up Hugging Face model...\")\n",
    "\n",
    "    model_name = \"microsoft/resnet-50\"\n",
    "    model = AutoModelForImageClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=2,  # blocked vs landed\n",
    "        ignore_mismatched_sizes=True\n",
    "    )\n",
    "\n",
    "    print(f\"‚úÖ Model loaded: {model_name}\")\n",
    "    print(f\" Number of classes: 2 (blocked/landed)\")\n",
    "\n",
    "    return model\n",
    "\n",
    "# Setup model\n",
    "model = setup_huggingface_model()\n",
    "\n",
    "# Display model info\n",
    "print(f\"\\nüìà Model Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"üîß Trainable Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748
    },
    "id": "PzUyXR-2L7Eg",
    "outputId": "770d3de7-6106-4d02-ea1f-281e5a122e1b"
   },
   "outputs": [],
   "source": [
    "# Training arguments - FIXED for older transformers version\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./punch-detection-model\",\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    warmup_steps=100,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=False,\n",
    "    report_to=None,\n",
    ")\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=processor,\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting model training...\")\n",
    "print(f\"üìä Training for {training_args.num_train_epochs} epochs\")\n",
    "print(f\"üéØ Batch size: {training_args.per_device_train_batch_size}\")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Save the model\n",
    "trainer.save_model(\"./punch-detection-model\")\n",
    "print(\"‚úÖ Model trained and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "_zj-erHXL--t",
    "outputId": "fa0fac96-25e2-4102-edea-a6f7fad4d045"
   },
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "print(\"üìä Evaluating model performance...\")\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "print(f\"\\n Evaluation Results:\")\n",
    "print(f\"   Loss: {eval_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Calculate accuracy manually if not available\n",
    "if 'eval_accuracy' not in eval_results:\n",
    "    print(\"   Accuracy: Calculating manually...\")\n",
    "\n",
    "    # Get predictions\n",
    "    predictions = trainer.predict(eval_dataset)\n",
    "    predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
    "    true_labels = predictions.label_ids\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = np.mean(predicted_labels == true_labels)\n",
    "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
    "else:\n",
    "    print(f\"   Accuracy: {eval_results['eval_accuracy']:.4f}\")\n",
    "\n",
    "# Plot training history - FIXED VERSION\n",
    "if hasattr(trainer.state, 'log_history'):\n",
    "    history = trainer.state.log_history\n",
    "\n",
    "    # Extract metrics with proper filtering\n",
    "    eval_entries = [log for log in history if 'eval_loss' in log]\n",
    "    train_entries = [log for log in history if 'train_loss' in log]\n",
    "\n",
    "    if eval_entries and train_entries:\n",
    "        # Use eval entries as base since they have epochs\n",
    "        epochs = [log.get('epoch', 0) for log in eval_entries]\n",
    "        eval_loss = [log.get('eval_loss', 0) for log in eval_entries]\n",
    "\n",
    "        # Match train loss to eval epochs\n",
    "        train_loss = []\n",
    "        for epoch in epochs:\n",
    "            # Find closest train loss for this epoch\n",
    "            train_entry = next((log for log in train_entries if abs(log.get('epoch', 0) - epoch) < 0.1), None)\n",
    "            train_loss.append(train_entry.get('train_loss', 0) if train_entry else 0)\n",
    "\n",
    "        # Plot\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "        # Loss plot\n",
    "        ax1.plot(epochs, train_loss, 'b-', label='Training Loss', linewidth=2, marker='o')\n",
    "        ax1.plot(epochs, eval_loss, 'r-', label='Validation Loss', linewidth=2, marker='s')\n",
    "        ax1.set_title('Training & Validation Loss')\n",
    "        ax1.set_xlabel('Epoch')\n",
    "        ax1.set_ylabel('Loss')\n",
    "        ax1.legend()\n",
    "        ax1.grid(True)\n",
    "\n",
    "        # Accuracy plot (if available)\n",
    "        eval_acc_entries = [log for log in history if 'eval_accuracy' in log]\n",
    "        if eval_acc_entries:\n",
    "            eval_acc = [log.get('eval_accuracy', 0) for log in eval_acc_entries]\n",
    "            acc_epochs = [log.get('epoch', 0) for log in eval_acc_entries]\n",
    "            ax2.plot(acc_epochs, eval_acc, 'g-', label='Validation Accuracy', linewidth=2, marker='o')\n",
    "            ax2.set_title('Validation Accuracy')\n",
    "            ax2.set_xlabel('Epoch')\n",
    "            ax2.set_ylabel('Accuracy')\n",
    "            ax2.legend()\n",
    "            ax2.grid(True)\n",
    "        else:\n",
    "            ax2.text(0.5, 0.5, 'Accuracy data not available\\nfor plotting',\n",
    "                    ha='center', va='center', transform=ax2.transAxes, fontsize=12)\n",
    "            ax2.set_title('Validation Accuracy')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Insufficient training history for plotting\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No training history available for plotting\")\n",
    "\n",
    "print(f\"\\nüéâ Training Complete!\")\n",
    "print(f\"   Final Loss: {eval_results['eval_loss']:.4f}\")\n",
    "print(f\"   Final Accuracy: {accuracy:.4f}\")\n",
    "print(f\"   Model saved to: ./punch-detection-model/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 836
    },
    "id": "eVdNCmOSMBjF",
    "outputId": "f178f048-e550-4645-cd57-08ac28e5456c"
   },
   "outputs": [],
   "source": [
    "# Load trained model\n",
    "model = AutoModelForImageClassification.from_pretrained(\"./punch-detection-model\")\n",
    "processor = AutoImageProcessor.from_pretrained(\"./punch-detection-model\")\n",
    "\n",
    "def predict_punch(image_path):\n",
    "    \"\"\"Predict if a punch is blocked or landed\"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(image, return_tensors=\"pt\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        predicted_class = torch.argmax(predictions).item()\n",
    "        confidence = predictions[0][predicted_class].item()\n",
    "\n",
    "    return \"Blocked\" if predicted_class == 0 else \"Landed\", confidence\n",
    "\n",
    "# Test on sample images\n",
    "print(\"üß™ Testing model predictions...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "# Get sample images from each class\n",
    "blocked_samples = [f for f in os.listdir(blocked_dir) if f.endswith('.jpg')][:3]\n",
    "landed_samples = [f for f in os.listdir(landed_dir) if f.endswith('.jpg')][:3]\n",
    "\n",
    "for i, (sample, label) in enumerate(zip(blocked_samples + landed_samples, ['Blocked']*3 + ['Landed']*3)):\n",
    "    if i < 3:\n",
    "        img_path = os.path.join(blocked_dir, sample)\n",
    "    else:\n",
    "        img_path = os.path.join(landed_dir, sample)\n",
    "\n",
    "    prediction, confidence = predict_punch(img_path)\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].set_title(f'True: {label}\\nPred: {prediction} ({confidence:.2f})')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "    # Color code based on correctness\n",
    "    color = 'green' if prediction == label else 'red'\n",
    "    axes[i].text(0.5, -0.1, f'Confidence: {confidence:.2f}',\n",
    "                 transform=axes[i].transAxes, ha='center',\n",
    "                 bbox=dict(boxstyle='round', facecolor=color, alpha=0.7))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NPfMg63mUs70",
    "outputId": "3abbf4d6-ca9c-4337-c1a1-365e91f0db58"
   },
   "outputs": [],
   "source": [
    "# Create a ZIP file of your trained model\n",
    "!zip -r punch_detection_model.zip ./punch-detection-model/\n",
    "\n",
    "# Download the model\n",
    "from google.colab import files\n",
    "files.download('punch_detection_model.zip')\n",
    "\n",
    "print(\"‚úÖ Model downloaded! You can now use it in your local project.\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
